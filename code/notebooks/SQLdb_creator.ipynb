{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7925868",
   "metadata": {},
   "source": [
    "### **CSV to SQLite Converter**\n",
    "This script converts multiple CSV files into a single SQLite database, creating one table per CSV file.\n",
    "\n",
    "#### **How It Works**\n",
    "1. **Scans CSV folder** - Loops through all `.csv` files in the specified directory\n",
    "2. **Creates tables** - Each CSV becomes a table (filename = table name)\n",
    "3. **Auto-detects columns** - Reads the first row to generate column names\n",
    "4. **Imports data** - Loads all CSV data into the corresponding tables\n",
    "5. **Single database output** - All tables are stored in one `.db` file\n",
    "\n",
    "#### **Key Features**\n",
    "- âœ… Automatic column detection from CSV headers\n",
    "- âœ… Data type inference (INTEGER, REAL, TEXT)\n",
    "- âœ… Handles empty values (converts to NULL)\n",
    "- âœ… Batch processing with progress tracking\n",
    "- âœ… Database verification with statistics\n",
    "\n",
    "#### **Configuration**\n",
    "```python\n",
    "CSV_FILES_FOLDER = \"../data/csv_db/\"      # Input folder\n",
    "DB_FILE = \"../data/databases/combined.db\" # Output database\n",
    "```\n",
    "\n",
    "#### **Usage**\n",
    "Simply run the script - it automatically processes all CSV files in the input folder and generates a single SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6602ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ CrÃ©ation de la base de donnÃ©es: ../data/databases/movie.db\n",
      "\n",
      "\n",
      "==================================================\n",
      "ðŸ”„ Traitement de: amazon_prime_titles.csv\n",
      "âœ… Table 'amazon_prime_titles' crÃ©Ã©e avec 12 colonnes\n",
      "âœ… 9668 lignes importÃ©es dans 'amazon_prime_titles'\n",
      "\n",
      "==================================================\n",
      "ðŸ”„ Traitement de: disney_plus_titles.csv\n",
      "âœ… Table 'disney_plus_titles' crÃ©Ã©e avec 12 colonnes\n",
      "âœ… 1450 lignes importÃ©es dans 'disney_plus_titles'\n",
      "\n",
      "==================================================\n",
      "ðŸ”„ Traitement de: netflix_titles.csv\n",
      "âœ… Table 'netflix_titles' crÃ©Ã©e avec 12 colonnes\n",
      "âœ… 8807 lignes importÃ©es dans 'netflix_titles'\n",
      "\n",
      "==================================================\n",
      "ðŸ“Š STATISTIQUES DE LA BASE DE DONNÃ‰ES\n",
      "==================================================\n",
      "Nombre de tables: 3\n",
      "\n",
      "ðŸ“‹ Table 'amazon_prime_titles': 38672 lignes\n",
      "ðŸ“‹ Table 'disney_plus_titles': 5800 lignes\n",
      "ðŸ“‹ Table 'netflix_titles': 35228 lignes\n",
      "\n",
      "âœ… Base de donnÃ©es complÃ¨te crÃ©Ã©e: ../data/databases/movie.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "CSV_FILES_FOLDER = \"../data/csv_db/\"\n",
    "DB_FILE = \"../data/databases/movie.db\"\n",
    "\n",
    "def clean_column_name(name):\n",
    "    \"\"\"Nettoie le nom de colonne pour SQLite\"\"\"\n",
    "    return name.strip().replace(' ', '_').replace('-', '_').lower()\n",
    "\n",
    "def clean_data(value):\n",
    "    \"\"\"Nettoie les valeurs du CSV\"\"\"\n",
    "    return None if value == \"\" else value\n",
    "\n",
    "def get_sql_type(value):\n",
    "    \"\"\"DÃ©termine le type SQL basique\"\"\"\n",
    "    if value is None or value == \"\":\n",
    "        return \"TEXT\"\n",
    "    try:\n",
    "        int(value)\n",
    "        return \"INTEGER\"\n",
    "    except:\n",
    "        try:\n",
    "            float(value)\n",
    "            return \"REAL\"\n",
    "        except:\n",
    "            return \"TEXT\"\n",
    "\n",
    "def create_table_from_csv(csv_file, table_name, conn):\n",
    "    \"\"\"CrÃ©e une table basÃ©e sur la structure du CSV\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    with open(csv_file, mode='r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        headers = next(csv_reader)\n",
    "        first_row = next(csv_reader, None)\n",
    "        \n",
    "        # Nettoyer les noms de colonnes\n",
    "        clean_headers = [clean_column_name(h) for h in headers]\n",
    "        \n",
    "        # CrÃ©er la dÃ©finition de la table\n",
    "        columns_def = []\n",
    "        for i, col in enumerate(clean_headers):\n",
    "            sql_type = get_sql_type(first_row[i] if first_row else None)\n",
    "            columns_def.append(f\"{col} {sql_type}\")\n",
    "        \n",
    "        # CrÃ©er la table\n",
    "        create_query = f\"CREATE TABLE IF NOT EXISTS {table_name} ({', '.join(columns_def)})\"\n",
    "        cursor.execute(create_query)\n",
    "        print(f\"âœ… Table '{table_name}' crÃ©Ã©e avec {len(clean_headers)} colonnes\")\n",
    "    \n",
    "    conn.commit()\n",
    "    return clean_headers\n",
    "\n",
    "def import_csv_to_table(csv_file, table_name, headers, conn):\n",
    "    \"\"\"Importe les donnÃ©es du CSV dans la table\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    with open(csv_file, mode='r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        \n",
    "        placeholders = ', '.join(['?' for _ in headers])\n",
    "        insert_query = f\"INSERT INTO {table_name} VALUES ({placeholders})\"\n",
    "        \n",
    "        row_count = 0\n",
    "        for row in csv_reader:\n",
    "            values = [clean_data(row[original_header]) for original_header in csv_reader.fieldnames]\n",
    "            cursor.execute(insert_query, values)\n",
    "            row_count += 1\n",
    "            \n",
    "            if row_count % 1000 == 0:\n",
    "                conn.commit()\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"âœ… {row_count} lignes importÃ©es dans '{table_name}'\")\n",
    "\n",
    "def verify_database(conn):\n",
    "    \"\"\"VÃ©rifie le contenu de la base de donnÃ©es\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Lister toutes les tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "    tables = cursor.fetchall()\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ðŸ“Š STATISTIQUES DE LA BASE DE DONNÃ‰ES\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Nombre de tables: {len(tables)}\\n\")\n",
    "    \n",
    "    for (table_name,) in tables:\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        print(f\"ðŸ“‹ Table '{table_name}': {count} lignes\")\n",
    "\n",
    "# Programme principal\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "print(f\"ðŸ”„ CrÃ©ation de la base de donnÃ©es: {DB_FILE}\\n\")\n",
    "\n",
    "for filename in os.listdir(CSV_FILES_FOLDER):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        csv_file = os.path.join(CSV_FILES_FOLDER, filename)\n",
    "        table_name = filename.replace(\".csv\", \"\").replace(\"-\", \"_\").replace(\" \", \"_\").lower()\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ðŸ”„ Traitement de: {filename}\")\n",
    "        \n",
    "        headers = create_table_from_csv(csv_file, table_name, conn)\n",
    "        import_csv_to_table(csv_file, table_name, headers, conn)\n",
    "\n",
    "verify_database(conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"\\nâœ… Base de donnÃ©es complÃ¨te crÃ©Ã©e: {DB_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127e6acd",
   "metadata": {},
   "source": [
    "### **OMDB API Documentation Generator**\n",
    "\n",
    "Creates a structured JSON documentation of the OMDB API (Open Movie Database) to enrich movie data. This JSON file can be fed to LLMs for automated API interactions.\n",
    "\n",
    "#### **What It Does**\n",
    "\n",
    "1. **Defines API structure** in a Python dictionary\n",
    "2. **Exports to JSON** for easy consumption by LLMs or other tools\n",
    "3. **Documents all parameters** and response fields\n",
    "\n",
    "#### **Key Features**\n",
    "\n",
    "- âœ… API key requirement clearly marked\n",
    "- âœ… All parameters documented with examples\n",
    "- âœ… Response structure fully detailed\n",
    "- âœ… LLM-friendly format for automated requests\n",
    "- âœ… Human-readable JSON output\n",
    "\n",
    "#### **Usage**\n",
    "\n",
    "Run the script to generate `omdb_api_doc.json` - this file can be:\n",
    "- Fed to LLMs for API automation\n",
    "- Used as reference documentation\n",
    "- Integrated into data enrichment pipelines\n",
    "\n",
    "#### **API Access**\n",
    "\n",
    "Get your free API key at: http://www.omdbapi.com/apikey.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc628ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "CSV_FILES_FOLDER = \"../data/csv_db/\"\n",
    "DB_FILE = \"../data/databases/movie_2.db\"\n",
    "\n",
    "def clean_column_name(name):\n",
    "    \"\"\"Nettoie le nom de colonne pour SQLite\"\"\"\n",
    "    return name.strip().replace(' ', '_').replace('-', '_').lower()\n",
    "\n",
    "def clean_data(value):\n",
    "    \"\"\"Nettoie les valeurs du CSV\"\"\"\n",
    "    return None if value == \"\" else value\n",
    "\n",
    "def get_sql_type(value):\n",
    "    \"\"\"DÃ©termine le type SQL basique\"\"\"\n",
    "    if value is None or value == \"\":\n",
    "        return \"TEXT\"\n",
    "    try:\n",
    "        int(value)\n",
    "        return \"INTEGER\"\n",
    "    except:\n",
    "        try:\n",
    "            float(value)\n",
    "            return \"REAL\"\n",
    "        except:\n",
    "            return \"TEXT\"\n",
    "\n",
    "def create_table_from_csv(csv_file, table_name, conn):\n",
    "    \"\"\"CrÃ©e une table basÃ©e sur la structure du CSV avec ID prÃ©fixÃ©\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    with open(csv_file, mode='r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        headers = next(csv_reader)\n",
    "        first_row = next(csv_reader, None)\n",
    "        \n",
    "        # Nettoyer les noms de colonnes\n",
    "        clean_headers = [clean_column_name(h) for h in headers]\n",
    "        \n",
    "        # CrÃ©er la dÃ©finition de la table avec ID unique prÃ©fixÃ©\n",
    "        columns_def = [f\"unique_id TEXT PRIMARY KEY\"]  # ID unique pour toute la DB\n",
    "        \n",
    "        for i, col in enumerate(clean_headers):\n",
    "            sql_type = get_sql_type(first_row[i] if first_row else None)\n",
    "            columns_def.append(f\"{col} {sql_type}\")\n",
    "        \n",
    "        # CrÃ©er la table\n",
    "        create_query = f\"CREATE TABLE IF NOT EXISTS {table_name} ({', '.join(columns_def)})\"\n",
    "        cursor.execute(create_query)\n",
    "        print(f\"âœ… Table '{table_name}' crÃ©Ã©e avec {len(clean_headers) + 1} colonnes (dont unique_id)\")\n",
    "    \n",
    "    conn.commit()\n",
    "    return clean_headers\n",
    "\n",
    "def import_csv_to_table(csv_file, table_name, headers, conn):\n",
    "    \"\"\"Importe les donnÃ©es du CSV dans la table avec ID prÃ©fixÃ©\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    with open(csv_file, mode='r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        \n",
    "        # Ajouter unique_id dans les placeholders\n",
    "        placeholders = ', '.join(['?' for _ in range(len(headers) + 1)])\n",
    "        insert_query = f\"INSERT INTO {table_name} VALUES ({placeholders})\"\n",
    "        \n",
    "        row_count = 0\n",
    "        for row in csv_reader:\n",
    "            # CrÃ©er l'ID unique : table_name + \"_\" + row_number\n",
    "            unique_id = f\"{table_name}_{row_count + 1}\"\n",
    "            \n",
    "            # Extraire les valeurs du CSV\n",
    "            values = [clean_data(row[original_header]) for original_header in csv_reader.fieldnames]\n",
    "            \n",
    "            # InsÃ©rer avec unique_id en premiÃ¨re position\n",
    "            cursor.execute(insert_query, [unique_id] + values)\n",
    "            row_count += 1\n",
    "            \n",
    "            if row_count % 1000 == 0:\n",
    "                conn.commit()\n",
    "                print(f\"  ImportÃ© {row_count} lignes...\")\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"âœ… {row_count} lignes importÃ©es dans '{table_name}'\")\n",
    "\n",
    "def verify_database(conn):\n",
    "    \"\"\"VÃ©rifie le contenu de la base de donnÃ©es\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Lister toutes les tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "    tables = cursor.fetchall()\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ðŸ“Š STATISTIQUES DE LA BASE DE DONNÃ‰ES\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Nombre de tables: {len(tables)}\\n\")\n",
    "    \n",
    "    for (table_name,) in tables:\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        \n",
    "        # Afficher un exemple d'ID\n",
    "        cursor.execute(f\"SELECT unique_id FROM {table_name} LIMIT 1\")\n",
    "        sample_id = cursor.fetchone()\n",
    "        \n",
    "        print(f\"ðŸ“‹ Table '{table_name}': {count} lignes\")\n",
    "        if sample_id:\n",
    "            print(f\"   Exemple d'ID: {sample_id[0]}\")\n",
    "\n",
    "# Programme principal\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "print(f\"ðŸ”„ CrÃ©ation de la base de donnÃ©es: {DB_FILE}\\n\")\n",
    "\n",
    "for filename in os.listdir(CSV_FILES_FOLDER):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        csv_file = os.path.join(CSV_FILES_FOLDER, filename)\n",
    "        table_name = filename.replace(\".csv\", \"\").replace(\"-\", \"_\").replace(\" \", \"_\").lower()\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ðŸ”„ Traitement de: {filename}\")\n",
    "        print(f\"   Nom de table: {table_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        headers = create_table_from_csv(csv_file, table_name, conn)\n",
    "        import_csv_to_table(csv_file, table_name, headers, conn)\n",
    "\n",
    "verify_database(conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"\\nâœ… Base de donnÃ©es complÃ¨te crÃ©Ã©e: {DB_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b22e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to: C:\\Users\\Vincent\\GitHub\\Vincent-20-100\\Agentic_Systems_Project_Vlamy\\code\\omdb_api_doc.json\n",
      "\n",
      "Loaded successfully!\n",
      "Title example: Inception\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- 1. The whole documentation as a Python dict (valid JSON) ----\n",
    "omdb_doc = {\n",
    "    \"description\": (\n",
    "        \"This documentation outlines the structure and specifications of the OMDB API \"\n",
    "        \"(Open Movie Database). It is organized into two main dictionaries:\\n\"\n",
    "        '- \"arguments\": Defines all input parameters accepted by the API, split into two query modes:\\n'\n",
    "        \"    â€¢ by_id_or_title: Search by IMDb ID or exact title.\\n\"\n",
    "        \"    â€¢ by_search: Keyword-based search (fuzzy matching).\\n\"\n",
    "        \"  Each parameter includes: required status, data type, valid values, default value (if any), \"\n",
    "        \"clear description, and example.\\n\"\n",
    "        \"  Note: In by_id_or_title mode, **at least one of 'i' or 't' is required**.\\n\"\n",
    "        '- \"responses\": Describes the structure of the API\\'s returned data, with data type '\n",
    "        \"and example for each field.\\n\"\n",
    "        \"These dictionaries enable building valid OMDB API requests and automatically parsing responses.\\n\\n\"\n",
    "        \"**Important**: An API key (`apikey`) is **required** for all requests.\"\n",
    "    ),\n",
    "    \"base_url\": \"http://www.omdbapi.com/\",\n",
    "    \"arguments\": {\n",
    "        \"by_id_or_title\": {\n",
    "            \"apikey\": {\n",
    "                \"required\": True,\n",
    "                \"type\": \"str\",\n",
    "                \"description\": \"API key required to access the service. Get one at http://www.omdbapi.com/apikey.aspx\",\n",
    "                \"example\": \"apikey=12345678\"\n",
    "            },\n",
    "            \"i\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"description\": \"IMDb ID of the movie, series, or episode (format: 'tt' followed by 7 or 8 digits). *At least 'i' or 't' is required.*\",\n",
    "                \"example\": \"i=tt1285016\"\n",
    "            },\n",
    "            \"t\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"description\": \"Exact title of the movie, series, or episode. *At least 'i' or 't' is required.*\",\n",
    "                \"example\": \"t=Inception\"\n",
    "            },\n",
    "            \"type\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"valid_options\": [\"movie\", \"series\", \"episode\"],\n",
    "                \"default\": None,\n",
    "                \"description\": \"Type of result to return (movie, series, or episode).\",\n",
    "                \"example\": \"type=movie\"\n",
    "            },\n",
    "            \"y\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"description\": \"Year of release (4-digit year).\",\n",
    "                \"example\": \"y=2010\"\n",
    "            },\n",
    "            \"plot\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"valid_options\": [\"short\", \"full\"],\n",
    "                \"default\": \"short\",\n",
    "                \"description\": \"Return a short or full plot summary.\",\n",
    "                \"example\": \"plot=full\"\n",
    "            },\n",
    "            \"r\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"valid_options\": [\"json\", \"xml\"],\n",
    "                \"default\": \"json\",\n",
    "                \"description\": \"Response data format.\",\n",
    "                \"example\": \"r=json\"\n",
    "            },\n",
    "            \"callback\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"description\": \"Callback function name for JSONP support.\",\n",
    "                \"example\": \"callback=myFunction\"\n",
    "            },\n",
    "            \"v\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"default\": \"1\",\n",
    "                \"description\": \"API version (reserved for future use).\",\n",
    "                \"example\": \"v=1\"\n",
    "            }\n",
    "        },\n",
    "        \"by_search\": {\n",
    "            \"apikey\": {\n",
    "                \"required\": True,\n",
    "                \"type\": \"str\",\n",
    "                \"description\": \"API key required to access the service. Get one at http://www.omdbapi.com/apikey.aspx\",\n",
    "                \"example\": \"apikey=12345678\"\n",
    "            },\n",
    "            \"s\": {\n",
    "                \"required\": True,\n",
    "                \"type\": \"str\",\n",
    "                \"description\": \"Movie/series title to search for (keyword-based search).\",\n",
    "                \"example\": \"s=Joker\"\n",
    "            },\n",
    "            \"type\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"valid_options\": [\"movie\", \"series\", \"episode\"],\n",
    "                \"default\": None,\n",
    "                \"description\": \"Type of result to return (movie, series, or episode).\",\n",
    "                \"example\": \"type=movie\"\n",
    "            },\n",
    "            \"y\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"description\": \"Year of release (4-digit year).\",\n",
    "                \"example\": \"y=2019\"\n",
    "            },\n",
    "            \"r\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"valid_options\": [\"json\", \"xml\"],\n",
    "                \"default\": \"json\",\n",
    "                \"description\": \"Response data format.\",\n",
    "                \"example\": \"r=json\"\n",
    "            },\n",
    "            \"page\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"int\",\n",
    "                \"valid_options\": list(range(1, 101)),\n",
    "                \"default\": 1,\n",
    "                \"description\": \"Page number to return (1â€“100). Maximum 100 results per page.\",\n",
    "                \"example\": \"page=2\"\n",
    "            },\n",
    "            \"callback\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"description\": \"Callback function name for JSONP support.\",\n",
    "                \"example\": \"callback=myFunction\"\n",
    "            },\n",
    "            \"v\": {\n",
    "                \"required\": False,\n",
    "                \"type\": \"str\",\n",
    "                \"default\": \"1\",\n",
    "                \"description\": \"API version (reserved for future use).\",\n",
    "                \"example\": \"v=1\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"responses\": {\n",
    "        \"Title\": {\"type\": \"str\", \"description\": \"Title of the movie or series.\", \"example\": \"Inception\"},\n",
    "        \"Year\": {\"type\": \"str\", \"description\": \"Year of release (4-digit string).\", \"example\": \"2010\"},\n",
    "        \"Rated\": {\"type\": \"str\", \"description\": \"MPAA rating (e.g., 'PG-13', 'R') or 'N/A'.\", \"example\": \"PG-13\"},\n",
    "        \"Released\": {\"type\": \"str\", \"description\": \"Full release date (formatted as 'DD Mon YYYY').\", \"example\": \"16 Jul 2010\"},\n",
    "        \"Runtime\": {\"type\": \"str\", \"description\": \"Runtime in minutes (with ' min' suffix).\", \"example\": \"148 min\"},\n",
    "        \"Genre\": {\"type\": \"str\", \"description\": \"Comma-separated list of genres.\", \"example\": \"Action, Sci-Fi, Thriller\"},\n",
    "        \"Director\": {\"type\": \"str\", \"description\": \"Comma-separated list of directors. 'N/A' if unknown.\", \"example\": \"Christopher Nolan\"},\n",
    "        \"Writer\": {\"type\": \"str\", \"description\": \"Comma-separated list of writers. 'N/A' if unknown.\", \"example\": \"Christopher Nolan\"},\n",
    "        \"Actors\": {\"type\": \"str\", \"description\": \"Comma-separated list of lead actors. 'N/A' if unknown.\", \"example\": \"Leonardo DiCaprio, Ken Watanabe, Joseph Gordon-Levitt\"},\n",
    "        \"Plot\": {\"type\": \"str\", \"description\": \"Plot summary. Length depends on `plot=short` (default) or `plot=full`.\", \"example\": \"A thief who steals corporate secrets through dream-sharing technology...\"},\n",
    "        \"Language\": {\"type\": \"str\", \"description\": \"Comma-separated list of languages.\", \"example\": \"English, Japanese, French\"},\n",
    "        \"Country\": {\"type\": \"str\", \"description\": \"Comma-separated list of countries of origin.\", \"example\": \"USA, UK\"},\n",
    "        \"Awards\": {\"type\": \"str\", \"description\": \"Awards won/nominated. 'N/A' if none.\", \"example\": \"Won 4 Oscars. Another 152 wins & 204 nominations.\"},\n",
    "        \"Poster\": {\"type\": \"str\", \"description\": \"URL to the poster image. 'N/A' if not available.\", \"example\": \"https://m.media-amazon.com/images/M/MV5BMjAxMzY3NjcxNF5BMl5BanBnXkFtZTcwNTI5OTM0Mw@@._V1_SX300.jpg\"},\n",
    "        \"Ratings\": {\"type\": \"list[dict]\", \"description\": \"List of ratings from various sources. Each dict has 'Source' and 'Value'.\", \"example\": [\n",
    "            {\"Source\": \"Internet Movie Database\", \"Value\": \"8.8/10\"},\n",
    "            {\"Source\": \"Rotten Tomatoes\", \"Value\": \"87%\"},\n",
    "            {\"Source\": \"Metacritic\", \"Value\": \"74/100\"}\n",
    "        ]},\n",
    "        \"Metascore\": {\"type\": \"str\", \"description\": \"Metacritic score (0â€“100). 'N/A' if not available.\", \"example\": \"74\"},\n",
    "        \"imdbRating\": {\"type\": \"str\", \"description\": \"IMDb rating out of 10.\", \"example\": \"8.8\"},\n",
    "        \"imdbVotes\": {\"type\": \"str\", \"description\": \"Number of votes on IMDb (with commas).\", \"example\": \"2,345,678\"},\n",
    "        \"imdbID\": {\"type\": \"str\", \"description\": \"Unique IMDb ID (starts with 'tt').\", \"example\": \"tt1375666\"},\n",
    "        \"Type\": {\"type\": \"str\", \"description\": \"Content type: 'movie', 'series', or 'episode'.\", \"example\": \"movie\"},\n",
    "        \"DVD\": {\"type\": \"str\", \"description\": \"DVD release date ('DD Mon YYYY') or 'N/A'.\", \"example\": \"07 Dec 2010\"},\n",
    "        \"BoxOffice\": {\"type\": \"str\", \"description\": \"Box office earnings (formatted with '$'). 'N/A' if unknown.\", \"example\": \"$292,576,195\"},\n",
    "        \"Production\": {\"type\": \"str\", \"description\": \"Production company. 'N/A' if unknown.\", \"example\": \"Warner Bros., Legendary Entertainment\"},\n",
    "        \"Website\": {\"type\": \"str\", \"description\": \"Official website URL. 'N/A' if none.\", \"example\": \"http://inceptionmovie.warnerbros.com/\" },\n",
    "        \"Response\": {\"type\": \"str\", \"description\": \"Indicates if request was successful: 'True' or 'False'.\", \"example\": \"True\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# ---- 2. Write a *real* JSON file (pretty-printed) ----\n",
    "path = Path(\"doc\\\\omdb_api_doc.json\")\n",
    "path.write_text(json.dumps(omdb_doc, indent=4), encoding=\"utf-8\")\n",
    "print(f\"File written to: {path.resolve()}\")\n",
    "\n",
    "# ---- 3. Load it back (this will now work) ----\n",
    "with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    loaded = json.load(f)\n",
    "\n",
    "print(\"\\nLoaded successfully!\")\n",
    "print(\"Title example:\", loaded[\"responses\"][\"Title\"][\"example\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
